{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc16f11d-f53b-4ee1-a18a-9aed412bc18a",
   "metadata": {},
   "source": [
    "### Speed check with CPU and GPU\n",
    "While training batches with PyTorch, it is often better to use GPU as a calculation for reducing execution time. However, the allocated memory on the GPU is important to estimate to ensure it can run. For instance, in the code below, generating a tensor with a size of 100k x 100k is impossible. It is because the memory that should be allocated on my GPU (8Gb) is insufficient. Therefore, I had to use CPU and my SWAP area for this operation because my memory was not sufficient (32Gb). Therefore, it is very important to check the capability of the GPU.\n",
    "\n",
    "Another point is to determine at which point GPU passes CPU. For instance, a tensor with 100 x 100, won't any faster if it is generated in the GPU compared to CPU. At least, on my machine, it took same amount of time. Therefore, if there is a big batch and GPU is capable, then it is better to use GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c3d21-0126-4d78-b4b3-d5578aacb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(f'Function {func.__name__}{args} {kwargs} Took {total_time:.4f} seconds')\n",
    "        return result\n",
    "    return timeit_wrapper\n",
    "\n",
    "@timeit\n",
    "def torch_ones(x_dim, y_dim, device = \"cpu\"):\n",
    "    device = torch.device(device)\n",
    "    print('Using device:', device)\n",
    "    total = torch.ones(x_dim, y_dim, device=device)\n",
    "    return total\n",
    "\n",
    "torch_ones(100,100,device = \"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pinn",
   "language": "python",
   "name": "pinn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
